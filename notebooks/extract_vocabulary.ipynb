{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Noun phrases: ['Sebastian Thrun', 'self-driving cars', 'Google', 'few people', 'the company', 'him', 'I', 'you', 'very senior CEOs', 'major American car companies', 'my hand', 'I', 'Thrun', 'an interview', 'Recode']\nWords: [('when', 'ADV'), ('Sebastian', 'PROPN'), ('Thrun', 'PROPN'), ('start', 'VERB'), ('work', 'VERB'), ('on', 'ADP'), ('self', 'NOUN'), ('-', 'PUNCT'), ('drive', 'VERB'), ('car', 'NOUN'), ('at', 'ADP'), ('Google', 'PROPN'), ('in', 'ADP'), ('2007', 'NUM'), (',', 'PUNCT'), ('few', 'ADJ'), ('people', 'NOUN'), ('outside', 'ADP'), ('of', 'ADP'), ('the', 'DET'), ('company', 'NOUN'), ('take', 'VERB'), ('-PRON-', 'PRON'), ('seriously', 'ADV'), ('.', 'PUNCT'), ('\"', 'PUNCT'), ('-PRON-', 'PRON'), ('can', 'VERB'), ('tell', 'VERB'), ('-PRON-', 'PRON'), ('very', 'ADV'), ('senior', 'ADJ'), ('ceo', 'NOUN'), ('of', 'ADP'), ('major', 'ADJ'), ('american', 'ADJ'), ('car', 'NOUN'), ('company', 'NOUN'), ('would', 'VERB'), ('shake', 'VERB'), ('-PRON-', 'DET'), ('hand', 'NOUN'), ('and', 'CCONJ'), ('turn', 'VERB'), ('away', 'ADV'), ('because', 'SCONJ'), ('-PRON-', 'PRON'), ('be', 'AUX'), ('not', 'PART'), ('worth', 'ADJ'), ('talk', 'VERB'), ('to', 'ADP'), (',', 'PUNCT'), ('\"', 'PUNCT'), ('say', 'VERB'), ('Thrun', 'PROPN'), (',', 'PUNCT'), ('in', 'ADP'), ('an', 'DET'), ('interview', 'NOUN'), ('with', 'ADP'), ('Recode', 'PROPN'), ('early', 'ADV'), ('this', 'DET'), ('week', 'NOUN'), ('.', 'PUNCT')]\nSebastian Thrun PERSON\nGoogle ORG\n2007 DATE\nAmerican NORP\nThrun PERSON\nRecode LOC\nearlier this week DATE\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import spacy\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "text = (\"When Sebastian Thrun started working on self-driving cars at \"\n",
    "        \"Google in 2007, few people outside of the company took him \"\n",
    "        \"seriously. “I can tell you very senior CEOs of major American \"\n",
    "        \"car companies would shake my hand and turn away because I wasn’t \"\n",
    "        \"worth talking to,” said Thrun, in an interview with Recode earlier \"\n",
    "        \"this week.\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "print(\"Words:\", [(token.lemma_, token.pos_) for token in doc])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Somebody once told me that something tell me this I will was away from to that which is to be done to do thought that i think a thought \nNoun phrases: ['Somebody', 'me', 'something', 'me', 'I', 'to do thought', 'i', 'a thought']\nWords: [('somebody', 'PRON'), ('once', 'ADV'), ('tell', 'VERB'), ('-PRON-', 'PRON'), ('that', 'SCONJ'), ('something', 'PRON'), ('tell', 'VERB'), ('-PRON-', 'PRON'), ('this', 'DET'), ('-PRON-', 'PRON'), ('will', 'VERB'), ('be', 'AUX'), ('away', 'ADV'), ('from', 'ADP'), ('to', 'ADP'), ('that', 'DET'), ('which', 'DET'), ('be', 'AUX'), ('to', 'PART'), ('be', 'AUX'), ('do', 'VERB'), ('to', 'PART'), ('do', 'AUX'), ('thought', 'NOUN'), ('that', 'SCONJ'), ('i', 'PRON'), ('think', 'VERB'), ('a', 'DET'), ('thought', 'NOUN')]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "text_with_duplicates = (\"Somebody once told me that \"\n",
    "                        \"something tell me this \"\n",
    "                        \"I will was away from to that \"\n",
    "                        \"which is to be done to do \"\n",
    "                        \"thought that i think a thought \")\n",
    "print(text_with_duplicates)\n",
    "doc_with_duplicates = nlp(text_with_duplicates)\n",
    "\n",
    "# Analyze syntax\n",
    "print(\"Noun phrases:\", [chunk.text for chunk in doc_with_duplicates.noun_chunks])\n",
    "print(\"Words:\", [(token.lemma_, token.pos_) for token in doc_with_duplicates])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc_with_duplicates.ents:\n",
    "    print(entity.text, entity.label_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}